{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Files\n",
    "\n",
    "# Path to the folder containing the stock CSV files\n",
    "stock_data_folder = '../Data/yfinance_data/'\n",
    "\n",
    "# Load all CSV files into a list of DataFrames\n",
    "csv_files = glob.glob(os.path.join(stock_data_folder, \"*.csv\"))\n",
    "\n",
    "# Combine all the CSV files into one DataFrame\n",
    "stock_df_list = [pd.read_csv(file) for file in csv_files]\n",
    "combined_stock_df = pd.concat(stock_df_list, ignore_index=True)\n",
    "\n",
    "# Convert Date column to datetime64[ns] format\n",
    "combined_stock_df['Date'] = pd.to_datetime(combined_stock_df['Date'], errors='coerce')\n",
    "\n",
    "# Check if the conversion worked and if there are any NaT values\n",
    "print(combined_stock_df['Date'].dtypes)  # Should be datetime64[ns]\n",
    "print(combined_stock_df['Date'].isnull().sum())  # Check for NaT values\n",
    "\n",
    "\n",
    "# Load the news data\n",
    "news_df = pd.read_csv('../Data/raw_analyst_ratings.csv')\n",
    "\n",
    "# Convert news date column to datetime64[ns], removing timezones if necessary\n",
    "news_df = news_df.rename(columns={'date': 'Date'})\n",
    "news_df['Date'] = pd.to_datetime(news_df['Date'], errors='coerce')\n",
    "\n",
    "# If there is timezone information, remove it\n",
    "news_df['Date'] = news_df['Date'].dt.tz_localize(None)\n",
    "\n",
    "# Check the types to ensure date columns match\n",
    "print(news_df['Date'].dtypes)  # Should be datetime64[ns]\n",
    "print(news_df['Date'].isnull().sum())  # Check for NaT values\n",
    "\n",
    "# Drop rows with NaT in date columns\n",
    "combined_stock_df.dropna(subset=['Date'], inplace=True)\n",
    "news_df.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "# Merge the news and combined stock data based on the date\n",
    "merged_df = pd.merge(combined_stock_df, news_df, left_on='Date', right_on='Date', how='inner')\n",
    "\n",
    "# Check the merged dataset\n",
    "print(\"Merged Data Shape:\", merged_df.shape)\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both Date columns are datetime without timezone or time components\n",
    "news_df['Date'] = pd.to_datetime(news_df['Date']).dt.date\n",
    "combined_stock_df['Date'] = pd.to_datetime(combined_stock_df['Date']).dt.date\n",
    "\n",
    "# Confirm both columns are now properly aligned\n",
    "print(news_df['Date'].dtype)\n",
    "print(combined_stock_df['Date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip any leading/trailing whitespace\n",
    "news_df['Date'] = news_df['Date'].astype(str).str.strip()\n",
    "combined_stock_df['Date'] = combined_stock_df['Date'].astype(str).str.strip()\n",
    "\n",
    "# Convert them back to datetime\n",
    "news_df['Date'] = pd.to_datetime(news_df['Date'])\n",
    "combined_stock_df['Date'] = pd.to_datetime(combined_stock_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique dates in both datasets\n",
    "news_dates = set(news_df['Date'].unique())\n",
    "stock_dates = set(combined_stock_df['Date'].unique())\n",
    "\n",
    "# Check if there are any overlaps\n",
    "common_dates = news_dates.intersection(stock_dates)\n",
    "print(f\"Number of common dates: {len(common_dates)}\")\n",
    "\n",
    "# Optionally, print a few common dates\n",
    "print(list(common_dates)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left join\n",
    "debug_merge = pd.merge(news_df, combined_stock_df, on='Date', how='left')\n",
    "\n",
    "# Display rows where there are no matches from the stock data\n",
    "missing_matches = debug_merge[debug_merge['Open'].isnull()]\n",
    "print(missing_matches[['Date', 'headline', 'publisher']].head())\n",
    "\n",
    "# Check the shape of the missing_matches DataFrame\n",
    "print(\"Number of missing matches:\", missing_matches.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " sentiment analysis using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to calculate sentiment using TextBlob\n",
    "def get_sentiment(headline):\n",
    "    analysis = TextBlob(headline)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Apply sentiment analysis on the news headlines\n",
    "debug_merge['sentiment'] = debug_merge['headline'].apply(get_sentiment)\n",
    "\n",
    "# Check sentiment scores\n",
    "print(debug_merge[['headline', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Daily Stock Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "debug_merge['Daily_Return'] = debug_merge['Close'].pct_change()\n",
    "\n",
    "# Drop rows with NaN values (resulting from the pct_change calculation)\n",
    "debug_merge = debug_merge.dropna()\n",
    "\n",
    "# Display the first few rows with daily returns\n",
    "print(debug_merge[['Date', 'Close', 'Daily_Return']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sentiment scores by date (average sentiment)\n",
    "daily_sentiment = debug_merge.groupby('Date')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Merge aggregated sentiment scores with daily returns\n",
    "final_df = pd.merge(daily_sentiment, debug_merge[['Date', 'Daily_Return']], on='Date')\n",
    "\n",
    "# Display the final dataset for correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation\n",
    "correlation = final_df['sentiment'].corr(final_df['Daily_Return'])\n",
    "\n",
    "print(f'Correlation between news sentiment and stock returns: {correlation:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a scatter plot with a regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='sentiment', y='Daily_Return', data=final_df, scatter_kws={'alpha':0.5}, line_kws={\"color\":\"red\"})\n",
    "plt.title('Sentiment vs. Stock Returns')\n",
    "plt.xlabel('Average Daily Sentiment')\n",
    "plt.ylabel('Daily Stock Return (%)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
