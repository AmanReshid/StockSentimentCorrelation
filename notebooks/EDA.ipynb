{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data \n",
    "\n",
    "df = pd.read_csv(\"../data/raw_analyst_ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset for a quick overview\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic descriptive statistics of the dataset\n",
    "print(\"\\nDescriptive statistics of numeric columns:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime (automatically handles different formats)\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Make timezone-naive by localizing to None if timezone information exists\n",
    "df['date'] = df['date'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data: Drop rows with missing headlines or dates\n",
    "df.dropna(subset=['headline', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of the 'headline_length'\n",
    "df['headline_length'] = df['headline'].apply(len)\n",
    "print(\"\\nDescriptive statistics for headline length:\")\n",
    "print(df['headline_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of headline lengths\n",
    "sns.histplot(df['headline_length'], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Headline Lengths\")\n",
    "plt.xlabel(\"Headline Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Analysis(Sentiment analysis )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to calculate sentiment polarity\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Apply sentiment analysis to each headline\n",
    "df['sentiment'] = df['headline'].apply(get_sentiment)\n",
    "\n",
    "# Classify the sentiment as positive, negative, or neutral\n",
    "df['sentiment_label'] = df['sentiment'].apply(lambda x: 'positive' if x > 0 else ('negative' if x < 0 else 'neutral'))\n",
    "\n",
    "# Display sentiment counts\n",
    "print(df['sentiment_label'].value_counts())\n",
    "\n",
    "# Plot the distribution of sentiment labels\n",
    "sns.countplot(x='sentiment_label', data=df)\n",
    "plt.title(\"Distribution of Sentiment Labels\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling and Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# Function to clean text by removing punctuation and stopwords\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    words = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Clean headlines\n",
    "df['cleaned_headline'] = df['headline'].apply(clean_text)\n",
    "\n",
    "# Extract common keywords using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=20)\n",
    "X = vectorizer.fit_transform(df['cleaned_headline'])\n",
    "keywords = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the top 20 keywords\n",
    "print(\"Top 20 keywords:\")\n",
    "print(keywords)\n",
    "\n",
    "# Plot the frequency of the top keywords\n",
    "keyword_counts = X.toarray().sum(axis=0)\n",
    "sns.barplot(x=keywords, y=keyword_counts)\n",
    "plt.title(\"Top 20 Keywords in Headlines\")\n",
    "plt.xlabel(\"Keywords\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily article count\n",
    "plt.figure(figsize=(12, 6))\n",
    "daily_article_count.plot()\n",
    "plt.title(\"Daily Article Count\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting Spikes in Publication Frequency\n",
    "\n",
    "# Define a threshold for identifying spikes (e.g., mean + 2 standard deviations)\n",
    "mean_count = daily_article_count.mean()\n",
    "std_count = daily_article_count.std()\n",
    "threshold = mean_count + 2 * std_count\n",
    "\n",
    "# Identify days with spikes in publication frequency\n",
    "spike_days = daily_article_count[daily_article_count > threshold]\n",
    "\n",
    "# Plot daily publication count with spikes highlighted\n",
    "plt.figure(figsize=(12, 6))\n",
    "daily_article_count.plot(label='Daily Article Count', color='gray')\n",
    "plt.scatter(spike_days.index, spike_days.values, color='red', label='Spikes', s=100, zorder=5)\n",
    "plt.axhline(y=threshold, color='blue', linestyle='--', label=f'Spike Threshold ({round(threshold, 2)})')\n",
    "plt.title(\"Daily Article Count with Detected Spikes\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Publication Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hour of publication from the datetime index\n",
    "df['hour'] = df.index.hour\n",
    "\n",
    "# Count the number of articles published at each hour\n",
    "hourly_article_count = df['hour'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the distribution of publishing times by hour\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=hourly_article_count.index, y=hourly_article_count.values, palette=\"viridis\")\n",
    "plt.title(\"Distribution of Articles by Hour of the Day\")\n",
    "plt.xlabel(\"Hour of the Day\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weekly Article Count\n",
    "\n",
    "# Time Series Analysis: Articles published per week\n",
    "weekly_article_count = df['headline'].resample('W').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weekly article count\n",
    "plt.figure(figsize=(12, 6))\n",
    "weekly_article_count.plot()\n",
    "plt.title(\"Weekly Article Count\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly and Yearly Article Count\n",
    "\n",
    "# Check publication trends by month and year\n",
    "monthly_article_count = df['headline'].resample('ME').count()\n",
    "yearly_article_count = df['headline'].resample('YE').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot monthly and yearly article counts\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "monthly_article_count.plot(ax=ax[0], color='blue')\n",
    "ax[0].set_title(\"Monthly Article Count\")\n",
    "ax[0].set_xlabel(\"Date\")\n",
    "ax[0].set_ylabel(\"Number of Articles\")\n",
    "\n",
    "yearly_article_count.plot(ax=ax[1], color='green')\n",
    "ax[1].set_title(\"Yearly Article Count\")\n",
    "ax[1].set_xlabel(\"Date\")\n",
    "ax[1].set_ylabel(\"Number of Articles\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publisher Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publisher Article Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Article count per publisher\n",
    "publisher_counts = df['publisher'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot article count per publisher\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=publisher_counts.index, y=publisher_counts.values)\n",
    "plt.title(\"Article Count by Publisher\")\n",
    "plt.xlabel(\"Publisher\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publisher Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 publishers by article count\n",
    "top_10_publishers = publisher_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 10 publishers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_10_publishers.index, y=top_10_publishers.values, palette=\"viridis\")\n",
    "plt.title(\"Top 10 Publishers by Number of Articles\")\n",
    "plt.xlabel(\"Publisher\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publisher Domain Analysis (for Email Addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if publishers are emails (simplified example)\n",
    "email_publishers = df[df['publisher'].str.contains(\"@\")]\n",
    "\n",
    "# Extract domains from email addresses\n",
    "email_publishers['domain'] = email_publishers['publisher'].apply(lambda x: x.split('@')[-1])\n",
    "\n",
    "# Count articles per domain\n",
    "domain_counts = email_publishers['domain'].value_counts()\n",
    "\n",
    "# Display top domains\n",
    "print(\"Top domains by number of articles:\")\n",
    "print(domain_counts.head(10))\n",
    "\n",
    "# Plot article count per domain\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=domain_counts.index, y=domain_counts.values)\n",
    "plt.title(\"Article Count by Domain\")\n",
    "plt.xlabel(\"Domain\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
